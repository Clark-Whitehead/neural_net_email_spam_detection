{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5_attempt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvtB7md0iLW1"
      },
      "source": [
        "# Perceptron SMS Spam Filter\n",
        "\n",
        "Clark - Whitehead\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u41n0EjshCqe",
        "outputId": "2ffbf5de-49a4-463f-c084-5ef7859f7edf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# These are bash commands (not python) that download and unzip the data.\n",
        "!wget archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
        "!unzip smsspamcollection.zip"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-11 09:55:38--  http://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 203415 (199K) [application/x-httpd-php]\n",
            "Saving to: ‘smsspamcollection.zip.1’\n",
            "\n",
            "smsspamcollection.z 100%[===================>] 198.65K  1.20MB/s    in 0.2s    \n",
            "\n",
            "2020-11-11 09:55:38 (1.20 MB/s) - ‘smsspamcollection.zip.1’ saved [203415/203415]\n",
            "\n",
            "Archive:  smsspamcollection.zip\n",
            "replace SMSSpamCollection? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace readme? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiQYtiq2iD3X"
      },
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import re  # Regular Expressions library\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def sanitize(sms: str):\n",
        "  '''\n",
        "  Sanitize a sms string by removing weird characters and changing to lowercase.\n",
        "  Input: string\n",
        "  Return: sanitized string\n",
        "  '''\n",
        "  sms = re.sub('[^A-Za-z ]', '', sms) # Substitute weird characters with empty str.\n",
        "  sms = sms.lower() # Force lowercase.\n",
        "  return sms\n",
        "\n",
        "def load_data():\n",
        "  ''' \n",
        "  Reads the SMS dataset, converts to two-class bag-of-words representation.\n",
        "  Returns:\n",
        "    X: Numpy matrix entry i,j is the number of times word j appears in sms i.\n",
        "    Y: Numpy vector entry i is 1 if sms i is spam, otherwise 0.\n",
        "  '''\n",
        "  # Read csv file.\n",
        "  filename = 'SMSSpamCollection' # This file must exist in local directory.\n",
        "  data = []\n",
        "  for line in open(filename, 'r').readlines():\n",
        "    line = line.split('\\t') # Split two columns separated by tab.\n",
        "    label = 1 if line[0]=='spam' else 0 # First column is 'ham' or 'spam'\n",
        "    sms = line[1] # Second column is sms.\n",
        "    sms = sanitize(sms)\n",
        "    data.append((label, sms))\n",
        "    \n",
        "  # Supplement with some custom sms examples.\n",
        "  data.append((0, sanitize('call me maybe? -carly')))\n",
        "  data.append((1, sanitize('please call to you claim your prize')))\n",
        "\n",
        "  # print(data)\n",
        "\n",
        "  # Tokenize data.\n",
        "  tokenizer = CountVectorizer(max_features=8603) # Set max number of tokens.\n",
        "  Y = np.array([x[0] for x in data])\n",
        "  corpus = [x[1] for x in data] # corpus is list of sms strings.\n",
        "  X = tokenizer.fit_transform(corpus).toarray()\n",
        "  vocabulary = tokenizer.vocabulary_\n",
        "  return X,Y,vocabulary\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Split train/test\n",
        "X,y,vocabulary = load_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 1)\n",
        "#X_test last index = 1840"
      ],
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWgHX5_YqeEP"
      },
      "source": [
        "\n",
        "## Class\n",
        "\n",
        "1. Implements a perceptron class with a *train* method that takes four arguments: X, y, learning rate, and max_epochs.\n",
        "2. Trains and tests a perceptron spam classifier on the dataset above. Reports the results in terms of accuracy and F1 score on the test set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RK-gx3UGJrm",
        "outputId": "29cd43b8-a2db-4bf6-a1d9-1af3801afbd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class perceptron:\n",
        "\n",
        "  def train(self, x, y, lr, maxE):\n",
        "\n",
        "    #x.shape[0] = 3735\n",
        "    #x.shape[1] = 8603\n",
        "\n",
        "\n",
        "    training_outputs = y\n",
        "\n",
        "    synaptic_weights = np.random.random((x.shape[1], 1))\n",
        "\n",
        "    b = 0\n",
        "\n",
        "    for iteration in range(maxE):\n",
        "\n",
        "      input_layer = x\n",
        "\n",
        "      outputs = sigmoid(np.dot(input_layer, synaptic_weights) - b)\n",
        "\n",
        "      error = outputs - training_outputs.reshape((3735, 1))\n",
        "\n",
        "      # adjustments = error * sigmoid_derivative(outputs) Can use Sigmoid_deriv as learning rate\n",
        "\n",
        "      adjustments = np.dot(input_layer.T, error * lr)\n",
        "\n",
        "      synaptic_weights -= adjustments\n",
        "\n",
        "      b -= sum(error * lr) / len(error)\n",
        "\n",
        "    if outputs[outputs >= .5].shape == y[y != 0].shape:\n",
        "\n",
        "      print(\"convereged\")\n",
        "      return synaptic_weights, b\n",
        "\n",
        "    return synaptic_weights, b\n",
        "\n",
        "  def test(self, x, y, w, b):\n",
        "\n",
        "\n",
        "    tp, fp, tn, fn = 0, 0, 0, 0\n",
        "\n",
        "    outputs = sigmoid(np.dot(x, w) - b)\n",
        "\n",
        "    tp = np.sum(np.logical_and(outputs >= .5, y.reshape(1841, 1) == 1))\n",
        "    fp = np.sum(np.logical_and(outputs >= .5, y.reshape(1841, 1) == 0))\n",
        "    tn = np.sum(np.logical_and(outputs < .5, y.reshape(1841, 1) == 0))\n",
        "    fn = np.sum(np.logical_and(outputs < .5, y.reshape(1841, 1) == 1))\n",
        "\n",
        "\n",
        "\n",
        "    return tp, fp, tn, fn\n",
        "\n",
        "\n",
        "aPerceptron = perceptron()\n",
        "\n",
        "learning_rate = .005\n",
        "max_ephocs = 100\n",
        "\n",
        "w, b = aPerceptron.train(X_train, y_train, learning_rate, max_ephocs)\n",
        "\n",
        "tp, fp, tn, fn = aPerceptron.test(X_test, y_test, w, b)\n",
        "\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "fScore = tp / (tp + ((1/2)*(fp + fn)))\n",
        "\n",
        "print(\"accuracy = \", accuracy)\n",
        "print(\"fscore = \", fScore)\n"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy =  0.9369907658881043\n",
            "fscore =  0.7867647058823529\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}